{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPzGwh2V25xJJ7Qh/kY97pJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maxsolomonhenry/mlp/blob/master/MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex5_sTE_iOCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9Pqbt8Q9lH_",
        "colab_type": "text"
      },
      "source": [
        "Two Layer Multilayer Perceptron Class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEBIWsV_zZoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Todo:\n",
        "#       dropout w/ probability.\n",
        "#       shuffle input X.\n",
        "\n",
        "\n",
        "class TwoLayerMLP:\n",
        "    def __init__(self, n_iter=1000, learning_rate=0.1, batch_size=30, hidden_layer_width=100,\n",
        "                 hidden_activation='relu'):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.batch_size = batch_size\n",
        "        self.hidden_layer_width = hidden_layer_width\n",
        "        self.hidden_activation = hidden_activation\n",
        "        self.V = torch.tensor([])\n",
        "        self.W = torch.tensor([])\n",
        "        self.inputs = torch.tensor([])\n",
        "        self.labels = torch.tensor([])\n",
        "        self.X = torch.tensor([])\n",
        "        self.Y = torch.tensor([])\n",
        "        self.Y_hat = torch.tensor([])\n",
        "        self.A1 = torch.tensor([])\n",
        "        self.Z1 = torch.tensor([])\n",
        "        self.Z2 = torch.tensor([])\n",
        "\n",
        "    @staticmethod\n",
        "    def hyperbolic_tangent(Z):\n",
        "        return Z.tanh()\n",
        "\n",
        "    @staticmethod\n",
        "    def hyperbolic_tangent_derivative(Z):\n",
        "        return 1 - Z.tanh() ** 2\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid(Z):\n",
        "        return 1 / (1 + torch.exp(-Z))\n",
        "\n",
        "    @staticmethod\n",
        "    def relu(Z):\n",
        "        return torch.clamp(Z, min=0)\n",
        "\n",
        "    @staticmethod\n",
        "    def relu_subgradient(Z):\n",
        "        return torch.clamp(torch.sign(Z), min=0)\n",
        "\n",
        "    @staticmethod\n",
        "    def softmax(Z):\n",
        "        # Transposing is to allow for row-wise operations (with built-in broadcasting)\n",
        "        max_dim = 1\n",
        "        if Z.ndim == 1:\n",
        "            max_dim = 0\n",
        "        Z0_transpose = Z.t() - Z.max(max_dim)[0]\n",
        "        Y_hat_transpose = torch.exp(Z0_transpose)\n",
        "        Y_hat_transpose /= Y_hat_transpose.sum(0)\n",
        "        Y_hat = Y_hat_transpose.t()\n",
        "        return Y_hat\n",
        "\n",
        "    @staticmethod\n",
        "    def cross_entropy_loss(y_hat, y):\n",
        "        return -torch.dot(y, torch.log(y_hat))\n",
        "\n",
        "    @staticmethod\n",
        "    def cross_entropy_grad(y_hat, y):\n",
        "        return -(y * 1 / y_hat) + (1 - y) * (1 / (1 - y_hat))\n",
        "\n",
        "    @staticmethod\n",
        "    def tensor_width(tensor):\n",
        "        if len(list(tensor.shape)) == 2:\n",
        "            return tensor.size(1)\n",
        "        elif len(list(tensor.shape)) == 1:\n",
        "            return 1\n",
        "        else:\n",
        "            raise ValueError('Tensor must be one or two dimensions.')\n",
        "\n",
        "    @staticmethod\n",
        "    def matrixify(y):\n",
        "        num_categories = int(y.max()) + 1\n",
        "        num_entries = len(y)\n",
        "        y = y.long()\n",
        "        Y = torch.zeros(num_entries, num_categories)\n",
        "        for i in range(num_entries):\n",
        "            Y[i, y[i]] = 1\n",
        "        return Y\n",
        "\n",
        "    def sigmoid_derivative(self, Z):\n",
        "        return self.sigmoid(Z) * (1 - self.sigmoid(Z))\n",
        "\n",
        "    def softmax_grad(self, Z):\n",
        "        # This code adapted from https://link.medium.com/OgOkKMjCz5\n",
        "        soft_max_result = self.softmax(Z)\n",
        "        reshaped = soft_max_result.view(-1, 1)\n",
        "        return torch.diagflat(reshaped) - torch.ger(reshaped[:, 0], reshaped[:, 0])\n",
        "\n",
        "    def activation(self, Z, output=False, derivative=False):\n",
        "        if not output:\n",
        "            function = self.hidden_activation\n",
        "        else:\n",
        "            function = 'softmax'\n",
        "\n",
        "        if not derivative:\n",
        "            if function == 'relu':\n",
        "                return self.relu(Z)\n",
        "            elif function == 'tanh':\n",
        "                return self.hyperbolic_tangent(Z)\n",
        "            elif function == 'sigmoid':\n",
        "                return self.sigmoid(Z)\n",
        "            elif function == 'softmax':\n",
        "                return self.softmax(Z)\n",
        "            else:\n",
        "                raise ValueError(\"Invalid activation function.\")\n",
        "        else:\n",
        "            if function == 'relu':\n",
        "                return self.relu_subgradient(Z)\n",
        "            elif function == 'tanh':\n",
        "                return self.hyperbolic_tangent_derivative(Z)\n",
        "            elif function == 'sigmoid':\n",
        "                return self.sigmoid_derivative(Z)\n",
        "            elif function == 'softmax':\n",
        "                return self.softmax_grad(Z)\n",
        "            else:\n",
        "                raise ValueError(\"Invalid activation function.\")\n",
        "\n",
        "    def verify_args(self):\n",
        "        if self.batch_size > self.inputs.size(0):\n",
        "            raise ValueError('Mini-batch size cannot be larger than data set.')\n",
        "\n",
        "    def initialize_weights(self):\n",
        "        num_categories = self.tensor_width(self.labels)\n",
        "        num_features = self.inputs.size(1)\n",
        "        self.W = torch.normal(0., 1., [num_features, self.hidden_layer_width])\n",
        "        self.W = self.W.to(self.device)\n",
        "        self.V = torch.normal(0., 1., [self.hidden_layer_width, num_categories])\n",
        "        self.V = self.V.to(self.device)\n",
        "\n",
        "    def set_ith_batch(self, i):\n",
        "        \"\"\"Selects a mini-batch of samples allowing for wraparound.\n",
        "        \"\"\"\n",
        "\n",
        "        first_sample = i * self.batch_size % self.labels.size(0)\n",
        "\n",
        "        if self.batch_size <= (self.inputs.size(0) - first_sample):\n",
        "            self.X = self.inputs[first_sample:first_sample + self.batch_size, :]\n",
        "            self.Y = self.labels[first_sample:first_sample + self.batch_size, :]\n",
        "        else:\n",
        "            input_end = self.inputs[first_sample:, :]\n",
        "            label_end = self.labels[first_sample:, :]\n",
        "            input_wraparound = self.inputs[:(self.batch_size - len(input_end)), :]\n",
        "            label_wraparound = self.labels[:(self.batch_size - len(label_end)), :]\n",
        "            self.X = torch.cat((input_end, input_wraparound))\n",
        "            self.Y = torch.cat((label_end, label_wraparound))\n",
        "        self.X = self.X.to(self.device)\n",
        "        self.Y = self.Y.to(self.device)\n",
        "\n",
        "    def predict_one_batch(self):\n",
        "        # N = number of instances in mini batch\n",
        "        # M = number of hidden units\n",
        "        # C = number of output categories\n",
        "        self.Z1 = torch.mm(self.X, self.W)  # (N x D) x (D x M) -> (N x M)\n",
        "        self.A1 = self.activation(self.Z1)\n",
        "        self.Z2 = torch.mm(self.A1, self.V)  # (N x M) x (M x C) -> (N x C)\n",
        "        self.Y_hat = self.activation(self.Z2, output=True)\n",
        "\n",
        "    def train_one_batch(self):\n",
        "        self.predict_one_batch()\n",
        "        delta_V = 0\n",
        "        delta_W = 0\n",
        "        for i in range(self.batch_size):\n",
        "            # Accumulate gradients for W and V.\n",
        "            loss_and_softmax_grad = self.Y_hat[i, :] - self.Y[i, :]\n",
        "            delta_V += torch.ger(self.A1[i, :], loss_and_softmax_grad)\n",
        "            row_calculation = torch.mv(self.V, loss_and_softmax_grad) * self.activation(self.Z1[i, :], derivative=True)\n",
        "            delta_W += torch.ger(self.X[i, :], row_calculation)\n",
        "        # Average gradients.\n",
        "        delta_V /= self.batch_size\n",
        "        delta_W /= self.batch_size\n",
        "        # Gradient descent.\n",
        "        self.V -= self.learning_rate * delta_V\n",
        "        self.W -= self.learning_rate * delta_W\n",
        "\n",
        "    def train(self, inputs, labels):\n",
        "        self.inputs = inputs\n",
        "        self.inputs = self.inputs.to(self.device)\n",
        "        self.labels = self.matrixify(labels)\n",
        "        self.labels = self.labels.to(self.device)\n",
        "        self.verify_args()\n",
        "        self.initialize_weights()\n",
        "        for i in range(self.n_iter):\n",
        "            self.set_ith_batch(i)\n",
        "            self.train_one_batch()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9GjT-mli6yx",
        "colab_type": "code",
        "outputId": "db07b75f-4f6f-4019-85d1-6847f8851928",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "batch_size = None\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10('/content/sample_data/', download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10('/content/sample_data/', download=True, train=False, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oh_HzLoPlOLu",
        "colab_type": "code",
        "outputId": "7c1e9bd0-26a5-48a9-b396-11e568feb4c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        }
      },
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "def image_show(img):\n",
        "  img = img/2 + 0.5\n",
        "  np_img = img.numpy()\n",
        "  plt.imshow(np.transpose(np_img, (1, 2, 0)))\n",
        "  plt.show()\n",
        "\n",
        "data_iter = iter(train_loader)\n",
        "images, labels = data_iter.next()\n",
        "\n",
        "image_show(torchvision.utils.make_grid(images))\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4))) "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-9fd875c6a715>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mimage_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%5s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-9fd875c6a715>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mimage_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%5s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5g6SQNzHQ-l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d39481b9-b8f7-4072-e070-38aafda1dd6c"
      },
      "source": [
        "labels"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6, 9, 0, 7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGjfe774l0Fb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, data in enumerate(train_loader):\n",
        "  inputs, labels = data\n",
        "  # Do stuff to a mini-batch here."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWH9PiITG9aV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# inputs.shape # 4 images, 3 channels of colour, 32 x 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA3PGGSpIcZh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "2f34a9d9-16cc-4216-8ceb-dc9445f66e35"
      },
      "source": [
        "test = torch.flatten(inputs[0]) # flatten for use with MLP"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-4f1fb0ae9563>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# flatten for use with MLP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
          ]
        }
      ]
    }
  ]
}